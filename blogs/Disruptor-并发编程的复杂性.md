# Disruptor-并发编程的复杂性
yuxuan 2019-03-25

这篇文章中涉及的内容主要来自
> [Disruptor: High performance alternative to bounded queues for exchanging data between concurrent threads](http://lmax-exchange.github.io/disruptor/files/Disruptor-1.0.pdf)

# 并发编程的复杂性
代码的并发执行涉及到两个方面：
- **互斥**：即资源的争用。
- **变化的可见性**：即控制_将修改暴露给其他线程_的时机。
如果能消除修改的的争用，就可能避免对互斥的需求，如果算法能保证资源只能被一个线程修改，互斥就不必要了。读操作和写操作都要求所有修改均对其他线程可见，此外，有争用的写操作对修改需要保证互斥。

并发编程中开销最大的部分是**带争用的写操作（contended write access）**，通常通过锁或者类似策略解决。

## 锁的开销
获取锁的时候，涉及到上下文切换（“context switch”，将控制权交还给内核，内核会挂起等待锁的所有线程，内核接管线程的时候可能会做一些额外的清理工作），
上下文切换的过程中，执行上下文（“execution context”）可能会丢失之前缓存的数据和指令，这种情形会严重影响性能。  
某些情况下，可以使用更快的用户态的锁，但只有**无资源争用**时才能有实际收益。
> 注：用户态的锁可能指使用CAS实现的自旋锁。

## “CAS”的开销
CAS(Compare And Swap)基于现代处理器实现的**原子指令**或**内部加锁**的指令(instruction**s**)，作为一种特殊的机器码指令，允许内存中的**字**的设定被有条件地作为原子操作。  
CAS可能成功或失败，如果失败，当前线程可以决定重试或者重新读取当前值。  
CAS不需要上下文切换，因此比加锁要更加高效，但并非没有额外开销，CAS需要处理器做如下操作：
- `lock its instruction pipeline` 以保证原子性。
- `employ a memory barrier` 以使内存变化对其他线程可见。

使用CAS和内存屏障（memory barrier）实现无锁算法非常复杂，并且很难验证其正确性。

Disruptor作者建议的理想算法是：对单个资源，单线程写入，多线程读取。这种情况下，多核环境中的读取需要内存屏障。

## Memory Barriers
处于性能考虑，现代处理器会做**指令乱序执行**以及内存与执行单元之间的**数据乱序存取**。处理器只需要保证程序逻辑产出相同结果，并不保证执行次序。在单线程程序中，这一点不是问题。但是当多个线程共享状态时，内存的修改依次序浮现就变得重要起来，保证次序使得数据能够成功交换。处理器使用内存屏障标记内存更新顺序重要的代码区域，使用内存屏障，多个线程之间可以获得硬件上的次序（hardware ordering）以及变化可见（visibility of change）。编译器可以插入内存屏障以保证编译后代码的执行次序，注意放置操作不需要额外的开销，处理器除了自己使用的硬件屏障之外，也会使用这种软件内存屏障。  
现代CPU比这一代的内存系统速度要快的多。为了衔接这一鸿沟，CPU使用彼此不相连的、高效快速的硬件哈希表作为复杂的缓存系统。不同核心之间使用的处理器缓存系统通过消息传递协议保持相干。除此之外，处理器还拥有“存储缓冲（store buffer）”和“失效队列（invalidate queue）”，“存储缓冲”用来写入缓存（offload writes to caches），“失效队列”的作用是：当写入将要发生时，使得缓存相干协议（cache coherency protocols）可以迅速确认失效消息。  
对于数据来说，写入完成后最新的值可能处于任何一个阶段，可能在寄存器、存储缓冲、多级缓存中的一级，或者在内存中。如果一个值被多个线程共享，这个值就需要以有序的方式可见，这种有序是通过缓存相干消息的协调交换来获得的。消息的及时生成可以由内存屏障来控制。
读取内存屏障（read memory barrier)使得CPU上执行的读取指令有序。CPU中的实现方式：当自己的缓存有修改时，CPU为其在失效队列中标记一个点。这就为内存屏障后的写操作提供了一个一致的视图（view of the world）。  
写入屏障（write barrier)使得CPU上执行的写入指令有序。CPU中的实现方式：在存储缓冲中标记一个点，从而使写操作通过缓存。这个屏障为写入屏障后的存储操作提供了一个有序的视图。  
全屏障使得存取均有序，但只对部署了该屏障的CPU有效。（A full memory barrier orders both loads and stores but only on the CPU that executes it. it代表barrier?）  
除了这三种原语，有些CPU还提供更多的变种，不过这三种原语已经足够帮助理解涉及到的复杂度了。在Java内存模型中，读写volatile字段时相应实现了读写屏障。  

## Cache Lines
; 重要数字：32-256 64 2048
对于高性能操作，现代处理器中缓存的使用方式至关重要。处理器在处理在缓存中的数据和指令时极其高效，相应地，缓存未命中时极其低效。  
硬件不支持以字节或者字为单位移动内存。为了更加高效，缓存以缓存行（cache-line）的方式组织，缓存行的大小通常在32-256字节之间，最常见的缓存行是64字节的，这也是缓存相干协议操作的粒度。这意味着如果两个变量在同一个缓存行中，但被不同的线程写入，这两个变量就会面对写入竞争的问题，就像它们是一个变量一样。这就是伪共享（"false sharing"）的概念。处于高性能的考虑，如果要最小化竞争，保证独立并发写入的变量不共享相同的缓存行是很重要的。  
当访问内存的方式可预测时，CPU可以预测将要被访问的内存并在后台预加载到缓存中，这就隐藏了访问主存的延迟开销。但是只有当处理器能探测到一种访问模式时生效，例如以可预测的“步长”遍历内存。当迭代一个数组的内容时，步长就是可预测的，因此内存会被预加载到缓存行中，这就使得访问尽可能地高效。为了被处理器注意到，正向或者方向迭代的步长都需要小于2048字节。需要注意，链表以及树这些数据结构一般会有分散在内存中的节点，并没有可预测的步长。内存中缺少一致的模式会限制系统预加载缓存行的能力，导致对主存的访问以及性能上2个数量级的下降。  

## 队列问题
; kafka好像是无界的。
队列通常使用链表或者数组作为元素的底层存储。如果in-memory的队列是无界的，在内存耗尽之前，许多问题会逐渐发酵而得不到检查，直至酿成大祸，这种情况发生在生产者超过消费者时。当生产者不会超过消费者能够得到保证，并且内存是一种珍贵资源时，无界队列可能是有用的，但是这终归存在这样一种风险：如果这个假设不能维持，队列就会无限增长。为了避免这种灾难，队列通常都会限制大小（有界的）。保持队列有界需要：使用数组作为底层实现，或者对其大小保持跟踪。  
队列实现中容易在队头、队尾和队列大小变量处产生写竞争。实际使用的典型情况下，队列总是接近满或者接近空的，因为消费者和生产者步调不一。队列极少在平衡状态下运行，除非平均生产速度和平均消费速度能够匹配。持续满和持续空的倾向导致高等级的争用*和/或*昂贵的缓存相干性。问题在于，即使通过使用锁或者CAS变量等并发对象将队头与队尾的运行机制分离，它们通常也占有相同的缓存行。  
管理生产者的关注点在队头，管理消费者的关注点在队尾，中间的存储节点使得并发实现的设计非常复杂，难以管理，不是在整个队列上使用一个大粒度的锁可以解决的。
在整个队列上为*放置（put）*和*拿取（take）*操作加大粒度锁很简洁，但意味着吞吐量的重大瓶颈。如果并发的关注点在队列的语义上被分离出来，任何实现将会变得非常复杂，除非是单生产者-单消费者的实现。  
在Java中关于队列的使用又一个更为深入的问题，因为队列是非常重大的垃圾来源。首先需要分配对象并将其放在队列中。其次，如果使用链表作为底层，还需要分配对象来代表链表中的节点。失去引用后，这些用来支持队列实现的对象需要被回收。

## 管道与图


# 更多参考资料
- [高效内存无锁队列 Disruptor](http://www.okyes.me/2016/11/01/disruptor.html)
- [论文中文翻译](http://blog.sina.com.cn/s/blog_68ffc7a4010150yl.html)
